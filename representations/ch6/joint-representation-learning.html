
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Network and Vertex feature joint representation learning &#8212; Network Machine Learning in Python</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Theoretical Results" href="../ch7/ch7.html" />
    <link rel="prev" title="Multigraph Representation Learning" href="multigraph-representation-learning.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Network Machine Learning in Python</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Preface
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   The Network Data Science Landscape
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-networks.html">
     Types of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/exercises.html">
     Exercises
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   End-to-end Biology Network Data Science Project
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/transformation-techniques.html">
     Transformation Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     Fine-Tune your Model
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   End-to-end Business Network Data Science Project
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch5/ch5.html">
   Why Use Statistical Models?
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/why-use-models.html">
     Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models.html">
     Single-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/single-network-models.html#references">
     References
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/multi-network-models.html">
     Multi-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/models-with-covariates.html">
     Network Models with Covariates
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="ch6.html">
   Learning Graph Representations
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="why-embed-networks.html">
     Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="random-walk-diffusion-methods.html">
     Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="graph-neural-networks.html">
     Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multigraph-representation-learning.html">
     Multigraph Representation Learning
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Network and Vertex feature joint representation learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch7/ch7.html">
   Theoretical Results
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     Theory for Graph Matching
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   Leveraging Representations for Single Graph Applications
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     Testing for Differences between Communities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/vertex-nomination.html">
     Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/anomaly-detection.html">
     Anomaly Detection
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   Algorithms for more than 2 graphs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     Testing for Significant Vertices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-communities.html">
     Testing for Significant Communities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch6/joint-representation-learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/representations/ch6/joint-representation-learning.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/representations/ch6/joint-representation-learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#making-a-model">
   Making a Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stochastic-block-model">
     Stochastic Block Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#covariates">
     Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#covariate-assisted-spectral-embedding">
   Covariate-Assisted Spectral Embedding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setting-a-better-weight">
     Setting A Better Weight
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#getting-the-range">
       Getting the Range
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#k-means">
       K-Means
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#variations-on-case">
     Variations on CASE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-graspologic">
     Using Graspologic
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#references">
       References
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="network-and-vertex-feature-joint-representation-learning">
<h1>Network and Vertex feature joint representation learning<a class="headerlink" href="#network-and-vertex-feature-joint-representation-learning" title="Permalink to this headline">¶</a></h1>
<p>In many network problems, we might have access to much more information than just the
collection of nodes and edges in the network. If we were investigating a social
network, for instance, we might have access to extra information about each
person – their gender, for instance, or their age. When we we embed a network, it seems
like we should be able to use this information - called “features” or “covariates” - to somehow improve our analysis.
Many of the techniques and tools that we’ll explore in this section use both the covariates and the network to
learn from new, holistic representations of the data available to us, jointly using both the network and the covariates.
These techniques are called joint representation learning.</p>
<p>There are two primary reasons that we might want to explore using node covariates in addition to networks. Firstly, they might improve our
standard embedding algorithms, like Laplacian and Adjacency Spectral Embedding.
For example, if the latent structure of the covariates lines up with the latent structure
of our network, then we could conceivably reduce noise, even if they don’t overlap perfectly. Second,
figuring out what the clusters of an embedding actually mean can sometimes be difficult, and using covariates
gives us to access to a natural structure. If we’re clustering brain networks, for instance,
covariate information telling us a location in the brain and name of brain region for each node might let us better
cluster by region.</p>
<p>In this section, we’ll explore different ways to learn from our data when we have access to these covariates in addition to our network. We’ll learn by example by making a toy network with its covariates.<br />
We’ll then explore <em>Covariate-Assisted Spectral Embedding</em> (CASE), a variation on spectral embedding. In CASE, instead of embedding the adjacency matrix or one of the many versions of the laplacian, we’ll combine the laplacian and our covariates into a new matrix and embed that.</p>
<div class="section" id="making-a-model">
<h2>Making a Model<a class="headerlink" href="#making-a-model" title="Permalink to this headline">¶</a></h2>
<p>First, we need a network model, and we also need some covariates to go along with it. The network part is pretty easy - we already have tools for simulating different networks, and so we’ll just use our go-to: the ever-popular Stochastic Block Model. For our SBM, we’ll use 1500 nodes and 3 communities, with pretty low connection probabilities both between and within nodes. To keep things simple, we’ll just use a single connection probability for all within-community edges ($p$), and another one for all between-community edges ($q$). Remember from chapter 4 that this is called a Planted Partition SBM.</p>
<div class="section" id="stochastic-block-model">
<h3>Stochastic Block Model<a class="headerlink" href="#stochastic-block-model" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>  <span class="c1"># TODO: don&#39;t do this, fix scatterplot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="mi">716</span><span class="n">f82802c82</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;graspologic&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Start with some simple parameters</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">N</span> <span class="o">//</span> <span class="mi">3</span>
<span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">15</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span>
              <span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span>
              <span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">]])</span>

<span class="c1"># Make our Stochastic Block Model</span>
<span class="n">A</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">],</span> <span class="n">B</span><span class="p">,</span> <span class="n">return_labels</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Our Stochastic Block Model&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/joint-representation-learning_7_0.png" src="../../_images/joint-representation-learning_7_0.png" />
</div>
</div>
</div>
<div class="section" id="covariates">
<h3>Covariates<a class="headerlink" href="#covariates" title="Permalink to this headline">¶</a></h3>
<p>Now, let’s generate some covariates. Remember, each node is associated with its own group of covariates that provide information about the node. We’ll organize these into a matrix, where each row contains the covariates associated with a particular node.</p>
<p>To keep things simple, we’ll have our covariates only take on true/false values - or, more specifically, 0 and 1. We’d also like a node’s covariates to look different depending on which community it belongs to. To that end, we’ll give each node 30 covariates, with the first 10 having a higher probability of 1 in the first community, the second having a higher probability of 1 in the second community, and the third having a higher probability of 1 in the third community.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bernoulli</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">LinearSegmentedColormap</span>

<span class="k">def</span> <span class="nf">gen_covariates</span><span class="p">(</span><span class="n">p1</span><span class="o">=.</span><span class="mi">8</span><span class="p">,</span> <span class="n">p2</span><span class="o">=.</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1500</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a matrix of covariates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_covariates</span> <span class="o">=</span> <span class="mi">30</span>

    <span class="n">bern</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_covariates</span><span class="o">//</span><span class="mi">3</span><span class="p">))</span>    
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">([[</span><span class="n">bern</span><span class="p">(</span><span class="n">p1</span><span class="p">),</span> <span class="n">bern</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span> <span class="n">bern</span><span class="p">(</span><span class="n">p2</span><span class="p">)],</span>
                  <span class="p">[</span><span class="n">bern</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span> <span class="n">bern</span><span class="p">(</span><span class="n">p1</span><span class="p">),</span> <span class="n">bern</span><span class="p">(</span><span class="n">p2</span><span class="p">)],</span>
                  <span class="p">[</span><span class="n">bern</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span> <span class="n">bern</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span> <span class="n">bern</span><span class="p">(</span><span class="n">p1</span><span class="p">)]])</span>

    <span class="k">return</span> <span class="n">X</span>

<span class="c1"># Generate a covariate matrix</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">gen_covariates</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can see a visualization of the covariates below.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot and make the axis look nice</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="s2">&quot;black&quot;</span><span class="p">]</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">LinearSegmentedColormap</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="s1">&#39;Custom&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Visualization of the covariates&quot;</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> 
       <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Rows containing covariates for their respective nodes&quot;</span><span class="p">);</span>

<span class="c1"># make the colorbar look nice</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">LinearSegmentedColormap</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="s1">&#39;Custom&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">))</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">])</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/joint-representation-learning_12_0.png" src="../../_images/joint-representation-learning_12_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="covariate-assisted-spectral-embedding">
<h2>Covariate-Assisted Spectral Embedding<a class="headerlink" href="#covariate-assisted-spectral-embedding" title="Permalink to this headline">¶</a></h2>
<p><i>Covariate-Assisted Spectral Embedding</i>, or CASE<sup>1</sup>, is a simple way of combining our graph and our covariates into a single model. In the most straightforward version of CASE, we use the graph’s regularized Laplacian matrix $L$ and a function of our covariate matrix $XX^T$ (where $X$ is just our covariate matrix, in which row $i$ contains the covariates associated with node $i$). Notice the word “regularized” - This means (from the Laplacian section earlier) that we are using $L_{\tau} = D_{\tau}^{-1/2} A D_{\tau}^{-1/2}$.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Remember that, in our case, $X$ only contains 0’s and 1’s. To interpret $XX^T$, remember from linear algebra that we’re taking the weighted sum (or, in math parlance, the dot product) of each row with each other row, as shown below:</p>
<div class="amsmath math notranslate nohighlight" id="equation-18c049dd-f6af-4fe1-9eba-d742a1e37944">
<span class="eqno">(2)<a class="headerlink" href="#equation-18c049dd-f6af-4fe1-9eba-d742a1e37944" title="Permalink to this equation">¶</a></span>\[\begin{align}
\begin{bmatrix}
1 \\
1 \\
1 \\
\end{bmatrix} \cdot 
\begin{bmatrix}
0 \\
1 \\
1 \\
\end{bmatrix} = 1\times 0 + 1\times 1 + 1\times 1 = 2
\end{align}\]</div>
</div>
<p>If there are two overlapping 1’s in the same place in rows $i$ and $j$, then their weighted sum will have a 1 in that place. The resulting value, $XX^T_{i, j}$ will be equal to the number of positions in which rows $i$ and $j$ both have ones. So, a position of $XX^T$ can be interpreted as measuring the “agreement” between rows $i$ and row $j$. The result is a matrix that looks fairly similar to our Laplacian!</p>
<p>The following Python code generates both matrices and visualizes them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">to_laplacian</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">L</span> <span class="o">=</span> <span class="n">to_laplacian</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;R-DAD&quot;</span><span class="p">)</span>
<span class="n">XXt</span> <span class="o">=</span> <span class="n">X</span><span class="nd">@X</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">L_ax</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;Regularized Laplacian&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">X_ax</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">(</span><span class="n">XXt</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Covariate matrix times its transpose&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/joint-representation-learning_18_0.png" src="../../_images/joint-representation-learning_18_0.png" />
</div>
</div>
<p>CASE simply sums these two matrices together, using a weight for $XX^T$ so that they both contribute equally to the result. Here, we’ll just use the ratio of the leading eigenvalues of our two matrices as our weight (henceforth known as $\alpha$). Later on, we’ll explore ways to pick a better $\alpha$.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a simple weight</span>
<span class="n">L_eigvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">L</span><span class="p">))</span>
<span class="n">XXt_eigvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">XXt</span><span class="p">))</span>

<span class="c1"># Ratio of the leading eigenvalues of L and XX^T</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="n">L_eigvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">XXt_eigvals</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Using our simple weight, combine our two matrices</span>
<span class="n">L_</span> <span class="o">=</span> <span class="n">L</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">X</span><span class="nd">@X</span><span class="o">.</span><span class="n">T</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">L_</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Our Combined Laplacian and covariates matrix&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/joint-representation-learning_20_0.png" src="../../_images/joint-representation-learning_20_0.png" />
</div>
</div>
<p>Everything works as usual from here: we decompose our matrix using an SVD, extracting the first two eigenvectors, and then we plot the rows to visualize our clustering.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">selectSVD</span>
<span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>
<span class="kn">import</span> <span class="nn">scipy</span>

<span class="k">def</span> <span class="nf">plot_latents</span><span class="p">(</span><span class="n">latent_positions</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">plot</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">latent_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">latent_positions</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> 
                           <span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;Set1&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">);</span>

<span class="k">def</span> <span class="nf">embed</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
    <span class="n">latents</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_clusters</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">latents</span>

<span class="n">latents</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">L_</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plot_latents</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Embedding our model&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/joint-representation-learning_22_0.png" src="../../_images/joint-representation-learning_22_0.png" />
</div>
</div>
<div class="section" id="setting-a-better-weight">
<h3>Setting A Better Weight<a class="headerlink" href="#setting-a-better-weight" title="Permalink to this headline">¶</a></h3>
<p>Our simple choice of the ratio of leading eigenvalues for our weight $\alpha$ is straightforward, but we can probably do better. If our covariate matrix is crappy – meaning, it doesn’t tell us much about our communities – we’d want a smaller weight so that our Laplacian is more emphasized when we embed. Similarly, if our Laplacian is crappy, we’d like a larger weight to emphasize the covariates.</p>
<p>In general, we’d simply like to embed in a way that makes our clustering better - meaning, if we label our communities, we’d like to be able to correctly retrieve as many labels after the embedding as possible with a clustering algorithm, and for our clusters to be as distinct as possible.</p>
<p>One reasonable way to accomplish this goal is to simply find a range of possible $\alpha$ values, embed for every value in this range, and then to simply check which values produce the best clustering.</p>
<div class="section" id="getting-the-range">
<h4>Getting the Range<a class="headerlink" href="#getting-the-range" title="Permalink to this headline">¶</a></h4>
<p>For somewhat complicated linear algebra reasons<sup>1</sup>, it’s fairly straightforward to get a range of tuning values: the minimum and maximum $\alpha$ is described by a set of two equations.</p>
<p>$\alpha_{min} = \frac{\lambda_K(L) - \lambda_{K+1}(L)}{\lambda_1(XX^T)}$ where $K$ is the number of embedding clusters, $\lambda_i(L)$ is the $i_{th}$ eigenvalue of $L$.</p>
<p>If the number of covariate dimensions is less than or equal to the number of clusters, then<br />
$\alpha_{max} = \frac{\lambda_1 (L)}{\lambda_R (XX^T)}$ where $R$ is the number of covariate dimensions</p>
<p>If the number of covariate dimensions is greater than the number of clusters, then<br />
$\alpha_{max} = \frac{\lambda_1(L)}{\lambda_K(XX^T) -\lambda_{K+1} (XX^T)}$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Number of covariates</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Number of clusters</span>

<span class="c1"># Remember, Python uses 0-indexing!</span>
<span class="n">amin</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_eigvals</span><span class="p">[</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">L_eigvals</span><span class="p">[</span><span class="n">K</span><span class="p">])</span> <span class="o">/</span> <span class="n">XXt_eigvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="n">R</span> <span class="o">&lt;=</span> <span class="n">K</span><span class="p">:</span>
    <span class="n">amax</span> <span class="o">=</span> <span class="n">L_eigvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">XXt_eigvals</span><span class="p">[</span><span class="n">R</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">R</span> <span class="o">&gt;</span> <span class="n">K</span><span class="p">:</span>
    <span class="n">amax</span> <span class="o">=</span> <span class="n">L_eigvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">XXt_eigvals</span><span class="p">[</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">XXt_eigvals</span><span class="p">[</span><span class="n">K</span><span class="p">])</span>
    
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Our minimum weight is </span><span class="si">{</span><span class="n">amin</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Our maximum weight is </span><span class="si">{</span><span class="n">amax</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Our minimum weight is 0.00000774.
Our maximum weight is 0.00042498.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="k-means">
<h4>K-Means<a class="headerlink" href="#k-means" title="Permalink to this headline">¶</a></h4>
<p>Let’s try it out. Our clustering algorithm of choice will be scikit-learn’s faster implementation of k-means. The K-means algorithm is a simple algorithm capable of clustering most datasets very quickly and efficiently, often in only a few iterations. It works by at first putting cluster centers in essentially random places, then iterating through a center-finding procedure until the cluster centers are in nice places. If you want more information, you can check out the original paper by Stuart Lloyd<sup>2</sup>.</p>
<p>We also need to define exactly what it means to check which values produce the best clustering. Fortunately, K-means comes out-of-the-box with exactly what we need: its objective function, the sum of squared distances of each point from its center. In KMeans, this is generally called the “inertia”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MiniBatchKMeans</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">cluster</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">XXt</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
    <span class="n">L_</span> <span class="o">=</span> <span class="n">L</span> <span class="o">+</span> <span class="n">alpha</span><span class="o">*</span><span class="n">XXt</span>
    <span class="n">latents</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">L_</span><span class="p">)</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_clusters</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">latents</span>


<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span class="n">tuning_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">amin</span><span class="p">,</span> <span class="n">amax</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">tuning_range</span><span class="p">:</span>
    <span class="n">L_</span> <span class="o">=</span> <span class="n">L</span> <span class="o">+</span> <span class="n">alpha</span><span class="o">*</span><span class="n">XXt</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">L_</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">latents</span><span class="p">)</span>
    <span class="n">alphas</span><span class="p">[</span><span class="n">alpha</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span>

<span class="n">best_alpha</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">alphas</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Our best alpha-value is </span><span class="si">{</span><span class="n">best_alpha</span><span class="si">:</span><span class="s2">0.8f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">latents</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="n">best_alpha</span><span class="o">*</span><span class="n">XXt</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
<span class="n">plot_latents</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Our embedding after tuning&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Our best alpha-value is 0.00000774
</pre></div>
</div>
<img alt="../../_images/joint-representation-learning_33_1.png" src="../../_images/joint-representation-learning_33_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">heatmap</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="n">best_alpha</span><span class="o">*</span><span class="n">XXt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/joint-representation-learning_34_1.png" src="../../_images/joint-representation-learning_34_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="variations-on-case">
<h3>Variations on CASE<a class="headerlink" href="#variations-on-case" title="Permalink to this headline">¶</a></h3>
<p>There are situations where changing the matrix that you embed is useful.</p>
<p><em>non-assortative</em><br />
If your graph is <em>non-assortative</em> - meaning, the between-block probabilities are greater than the within-block communities - it’s better to square your Laplacian. You end up embedding $LL + aXX^T$.</p>
<p><em>big graphs</em><br />
Since the tuning procedure is computationally expensive, you wouldn’t want to spend the time tuning $\alpha$ for larger graphs. There are a few options here: you can use a non-tuned version of alpha, or you can use a variant on classical correlation analysis<sup>3</sup> and simply embed $LX$.</p>
</div>
<div class="section" id="using-graspologic">
<h3>Using Graspologic<a class="headerlink" href="#using-graspologic" title="Permalink to this headline">¶</a></h3>
<p>Graspologic’s CovariateAssistedSpectralEmbedding class uses SVD decomposition to implement CASE, just like we just did earlier. The following code applies CASE to reduce the dimensionality of $L + aXX^T$ down to three dimensions, and then plots the second dimension against the third to show the clustering. You can also try the above variations on CASE with the <code class="docutils literal notranslate"><span class="pre">embedding_alg</span></code> parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">CovariateAssistedEmbedding</span> <span class="k">as</span> <span class="n">CASE</span>

<span class="n">casc</span> <span class="o">=</span> <span class="n">CASE</span><span class="p">(</span><span class="n">embedding_alg</span><span class="o">=</span><span class="s2">&quot;assortative&quot;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">latents</span> <span class="o">=</span> <span class="n">casc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">covariates</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
<span class="n">plot_latents</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Embedding our model using graspologic&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>amin=0.005519059, amax=0.297135065
alpha without tuning: 0.1314702072263226
[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.
[Parallel(n_jobs=7)]: Done   1 tasks      | elapsed:    9.6s
[Parallel(n_jobs=7)]: Done   2 tasks      | elapsed:    9.6s
[Parallel(n_jobs=7)]: Done   3 tasks      | elapsed:    9.6s
[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    9.6s
[Parallel(n_jobs=7)]: Done   5 tasks      | elapsed:    9.6s
[Parallel(n_jobs=7)]: Done   6 tasks      | elapsed:    9.7s
[Parallel(n_jobs=7)]: Done   7 tasks      | elapsed:    9.7s
[Parallel(n_jobs=7)]: Done   8 tasks      | elapsed:   19.2s
[Parallel(n_jobs=7)]: Done   9 tasks      | elapsed:   19.3s
[Parallel(n_jobs=7)]: Done  10 tasks      | elapsed:   19.3s
[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:   19.3s
[Parallel(n_jobs=7)]: Done  12 tasks      | elapsed:   19.3s
[Parallel(n_jobs=7)]: Done  13 tasks      | elapsed:   19.3s
[Parallel(n_jobs=7)]: Done  14 tasks      | elapsed:   19.3s
[Parallel(n_jobs=7)]: Done  15 tasks      | elapsed:   28.9s
[Parallel(n_jobs=7)]: Done  16 tasks      | elapsed:   28.9s
[Parallel(n_jobs=7)]: Done  17 tasks      | elapsed:   28.9s
[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed:   28.9s
[Parallel(n_jobs=7)]: Done  19 tasks      | elapsed:   28.9s
[Parallel(n_jobs=7)]: Done  20 tasks      | elapsed:   29.0s
[Parallel(n_jobs=7)]: Done  21 tasks      | elapsed:   29.0s
[Parallel(n_jobs=7)]: Done  22 tasks      | elapsed:   38.5s
[Parallel(n_jobs=7)]: Done  23 tasks      | elapsed:   38.5s
[Parallel(n_jobs=7)]: Done  24 tasks      | elapsed:   38.5s
[Parallel(n_jobs=7)]: Done  25 tasks      | elapsed:   38.6s
[Parallel(n_jobs=7)]: Done  26 tasks      | elapsed:   38.6s
[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   38.6s
[Parallel(n_jobs=7)]: Done  28 tasks      | elapsed:   38.6s
[Parallel(n_jobs=7)]: Done  29 tasks      | elapsed:   48.2s
[Parallel(n_jobs=7)]: Done  30 tasks      | elapsed:   48.3s
[Parallel(n_jobs=7)]: Done  31 tasks      | elapsed:   48.3s
[Parallel(n_jobs=7)]: Done  32 tasks      | elapsed:   48.3s
[Parallel(n_jobs=7)]: Done  33 tasks      | elapsed:   48.3s
[Parallel(n_jobs=7)]: Done  34 tasks      | elapsed:   48.3s
[Parallel(n_jobs=7)]: Done  35 tasks      | elapsed:   48.3s
[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   57.9s
[Parallel(n_jobs=7)]: Done  37 tasks      | elapsed:   57.9s
[Parallel(n_jobs=7)]: Done  38 tasks      | elapsed:   57.9s
[Parallel(n_jobs=7)]: Done  39 tasks      | elapsed:   58.0s
[Parallel(n_jobs=7)]: Done  40 tasks      | elapsed:   58.0s
[Parallel(n_jobs=7)]: Done  41 tasks      | elapsed:   58.0s
[Parallel(n_jobs=7)]: Done  42 tasks      | elapsed:   58.0s
[Parallel(n_jobs=7)]: Done  43 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  44 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  45 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  46 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  47 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  48 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  49 tasks      | elapsed:  1.1min
[Parallel(n_jobs=7)]: Done  50 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  51 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  52 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  53 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  54 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  55 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  56 tasks      | elapsed:  1.3min
[Parallel(n_jobs=7)]: Done  57 tasks      | elapsed:  1.4min
[Parallel(n_jobs=7)]: Done  58 tasks      | elapsed:  1.5min
[Parallel(n_jobs=7)]: Done  59 tasks      | elapsed:  1.5min
[Parallel(n_jobs=7)]: Done  60 tasks      | elapsed:  1.5min
[Parallel(n_jobs=7)]: Done  61 tasks      | elapsed:  1.5min
[Parallel(n_jobs=7)]: Done  62 tasks      | elapsed:  1.5min
[Parallel(n_jobs=7)]: Done  63 tasks      | elapsed:  1.5min
[Parallel(n_jobs=7)]: Done  64 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  65 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  66 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  67 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  68 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  69 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  70 tasks      | elapsed:  1.6min
[Parallel(n_jobs=7)]: Done  71 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  72 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  73 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  74 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  75 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  76 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  77 tasks      | elapsed:  1.8min
[Parallel(n_jobs=7)]: Done  78 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  79 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  80 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  81 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  82 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  83 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  84 tasks      | elapsed:  1.9min
[Parallel(n_jobs=7)]: Done  85 tasks      | elapsed:  2.1min
[Parallel(n_jobs=7)]: Done  86 tasks      | elapsed:  2.1min
[Parallel(n_jobs=7)]: Done  87 tasks      | elapsed:  2.1min
[Parallel(n_jobs=7)]: Done  89 out of 100 | elapsed:  2.1min remaining:   15.5s
[Parallel(n_jobs=7)]: Done  91 out of 100 | elapsed:  2.1min remaining:   12.4s
[Parallel(n_jobs=7)]: Done  93 out of 100 | elapsed:  2.2min remaining:   10.1s
[Parallel(n_jobs=7)]: Done  95 out of 100 | elapsed:  2.2min remaining:    7.1s
[Parallel(n_jobs=7)]: Done  97 out of 100 | elapsed:  2.2min remaining:    4.2s
[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:  2.3min finished
Best inertia at alpha=0.011410: 0.072114
</pre></div>
</div>
<img alt="../../_images/joint-representation-learning_39_1.png" src="../../_images/joint-representation-learning_39_1.png" />
</div>
</div>
<div class="section" id="references">
<h4>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h4>
<p>[1] N. Binkiewicz, J. T. Vogelstein, K. Rohe, Covariate-assisted spectral clustering, Biometrika, Volume 104, Issue 2, June 2017, Pages 361–377, https://doi.org/10.1093/biomet/asx008<br />
[2] Lloyd, S. (1982). Least squares quantization in PCM. IEEE transactions on information theory, 28(2), 129-137.<br />
[3] Hotelling, H. (1936). Relations between two sets of variates. Biometrika 28, 321–77.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="multigraph-representation-learning.html" title="previous page">Multigraph Representation Learning</a>
    <a class='right-next' id="next-link" href="../ch7/ch7.html" title="next page">Theoretical Results</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>