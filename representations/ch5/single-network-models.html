
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Single-Network Models &#8212; Network Machine Learning in Python</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multi-Network Models" href="multi-network-models.html" />
    <link rel="prev" title="Why Use Statistical Models?" href="why-use-models.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Network Machine Learning in Python</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Network Machine Learning in Python
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Data Science Landscape
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-networks.html">
     1.4. Types of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.5. Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/exercises.html">
     1.6. Exercises
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Data Science Project
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/discover-and-visualize.html">
     2.1. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.2. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/transformation-techniques.html">
     2.3. Transformation Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.4. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.5. Fine-Tune your Model
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Data Science Project
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch4/ch4.html">
   1. Properties of Networks as a Statistical Object
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/matrix-representations.html">
     1.1. Matrix Representations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/network-representations.html">
     1.2. Network Representations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/properties-of-networks.html">
     1.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/regularization.html">
     1.4. Regularization
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="ch5.html">
   2. Why Use Statistical Models?
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="why-use-models.html">
     Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Single-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="#references">
     References
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multi-network-models.html">
     Multi-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models-with-covariates.html">
     Network Models with Covariates
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch6/ch6.html">
   3. Learning Graph Representations
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters.html">
     3.1. Estimating Parameters in Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/why-embed-networks.html">
     3.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/random-walk-diffusion-methods.html">
     3.3. Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/graph-neural-networks.html">
     3.4. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/multigraph-representation-learning.html">
     3.5. Multigraph Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/joint-representation-learning.html">
     3.6. Joint Representation Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../ch7/ch7.html">
   4. Theoretical Results
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     4.1. Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     4.2. Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     4.3. Theory for Graph Matching
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   1. Leveraging Representations for Single Graph Applications
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     1.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     1.2. Testing for Differences between Communities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     1.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/vertex-nomination.html">
     1.4. Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/anomaly-detection.html">
     1.5. Anomaly Detection
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   2. Leveraging Representations for Multiple Graph Applications
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/two-sample-hypothesis.html">
     2.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/graph-matching-vertex.html">
     2.2. Graph Matching and Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/vertex-nomination.html">
     2.3. Vertex Nomination
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   3. Algorithms for more than 2 graphs
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     3.1. Testing for Significant Vertices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-communities.html">
     3.2. Testing for Significant Communities
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch5/single-network-models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/representations/ch5/single-network-models.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/representations/ch5/single-network-models.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Single-Network Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#erdos-renyi-er">
     Erdös-Rényi (ER)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stochastic-block-model-sbm">
     Stochastic Block Model (SBM)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#structured-independent-edge-model-siem">
     Structured Independent Edge Model (SIEM)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-dot-product-graph-rdpg">
     Random Dot Product Graph (RDPG)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalized-random-dot-product-graph-grdpg">
     Generalized Random Dot Product Graph (GRDPG)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#degree-corrected-models">
     Degree-Corrected Models
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inhomogeneous-erdos-renyi-ier">
     Inhomogeneous Erdos-Renyi (IER)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="single-network-models">
<h1>Single-Network Models<a class="headerlink" href="#single-network-models" title="Permalink to this headline">¶</a></h1>
<p>Consider a social network. A common question that we might have is how, exactly, we could describe the network in the simplest way possible. For instance, if we know nothing about the people, or how they might be connected in the social network, we might want to just say that a pair of people have a probability of being friends. On the other hand, if we know people within the social network are groups of students from different schools, we might want to say that people from the same school have a higher probability of being friends than people from different schools. The way we characterize the network in one of these (or other) ways is called the choice of the single-network model.</p>
<div class="section" id="erdos-renyi-er">
<h2>Erdös-Rényi (ER)<a class="headerlink" href="#erdos-renyi-er" title="Permalink to this headline">¶</a></h2>
<p>The simplest random network model is the Erdös Rényi (ER) model<sup>1</sup>. Consider the social network example explained above. If we do not know any patterns defining how people are or are not friends, the simplest possible thing to do with our network would be to assume that a given pair of people within our network have the same chance of being friends as any other selected pair of people. The Erdös Rényi model formalizes this relatively simple model with a single parameter:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(p\)</span>: an edge existence probability parameter governing how edges are connected.</p></li>
</ol>
<p>In an Erdös Rényi network, each pair of nodes is connected with probability <span class="math notranslate nohighlight">\(p\)</span>, and therefore not connected with probability <span class="math notranslate nohighlight">\(1-p\)</span>. Further, no other properties of the network (including which vertices an edge is incident, other edges within the network, or any other factors) influence whether a pair of vertices are connected. Statistically, we write that for each edge <span class="math notranslate nohighlight">\(A_{ij}\)</span>, that <span class="math notranslate nohighlight">\(A_{ij}\)</span> is sampled independently and identically from a <span class="math notranslate nohighlight">\(Bernoulli(p)\)</span> distribution. The word “independent” means that edges in the network occurring or not occurring do not affect one another. The word “identical” means that every edge in the network has the same probability <span class="math notranslate nohighlight">\(p\)</span> of being connected. If <span class="math notranslate nohighlight">\(\pmb A\)</span> is the adjacency matrix for an ER network with probability <span class="math notranslate nohighlight">\(p\)</span>, we write that <span class="math notranslate nohighlight">\(\pmb A \sim ER_n(p)\)</span>.</p>
<p>In practice, the ER model seems like it might be a little too simple to be useful. Why would it ever be useful to think that the best we can do to describe our network is to say that connections exist with some probability? Does this miss a <em>lot</em> of useful questions we might want to answer? Fortunately, there are a number of ways in which the simplicity of the ER model is useful. Given a probability and a number of nodes, we can easily describe the properties we would expect to see in a network if that network were ER. For instance, we know what the degree distribution of an ER network should look like. We can reverse this idea, too: given a network we think might <em>not</em> be ER, we could check whether it’s different in some way from a network which is ER. For instance, if we see a half of the nodes have a very high degree, and the rest of the nodes with a much lower degree, we can reasonably conclude the network might be more complex than can be described by the ER model. If this is the case, we might look for other, more complex, models that could describe our network.</p>
<div class="admonition-computing-the-expected-degree-in-an-erd-ouml-s-r-eacute-nyi-network admonition">
<p class="admonition-title">Computing the Expected Degree in an Erdös-Rényi Network</p>
<p>Suppose that <span class="math notranslate nohighlight">\((\mathcal V, \mathcal E)\)</span> is the topology of an undirected network with loops and adjacency matrix <span class="math notranslate nohighlight">\(\pmb A\)</span>. The network has <span class="math notranslate nohighlight">\(n\)</span> nodes <span class="math notranslate nohighlight">\(\mathcal V = (v_i)_{i = 1}^n\)</span>. Recall that the in an undirected, loopy network, node degree is <span class="math notranslate nohighlight">\(deg(v_i) = \sum_{j = 1}^n A_{ij}\)</span>. What is the expected degree of a given node <span class="math notranslate nohighlight">\(v_i\)</span> if <span class="math notranslate nohighlight">\(\mathcal G\)</span> were ER with probability parameter <span class="math notranslate nohighlight">\(p\)</span>?</p>
<p>To describe this, we will compute the expectated value of the degree <span class="math notranslate nohighlight">\(deg(v_i)\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i)\right] &amp;= \mathbb E\left[\sum_{j = 1}^n A_{ij}\right] \\
    &amp;= \sum_{j = 1}^n \mathbb E[A_{ij}]
\end{align*}\]</div>
<p>We use the <em>linearity of expectation</em> in the line above, which means that the expectation of a sum with a finite number of terms being summed over (<span class="math notranslate nohighlight">\(n\)</span>, in this case) is the sum of the expectations. Finally, by definition, all of the edges <span class="math notranslate nohighlight">\(A_{ij}\)</span> have the same distribution: <span class="math notranslate nohighlight">\(Bernoulli(p)\)</span>. The expected value of a random quantity which takes a Bernoulli distribution is just the probability <span class="math notranslate nohighlight">\(p\)</span>! Therefore:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i)\right] &amp;= \sum_{j = 1}^n p = n\cdot p
\end{align*}\]</div>
<p>Since all of the <span class="math notranslate nohighlight">\(n\)</span> terms being summed have the same expected value. This holds for <em>every</em> node <span class="math notranslate nohighlight">\(v_i\)</span>, which means that the expected degree of all nodes is an undirected ER network is the same.</p>
</div>
<p>The ER model is also useful for the development of new computational techniques to use on random networks. This is because even if the “best” model for a network is something much more complex, we can still calculate an edge probability <span class="math notranslate nohighlight">\(p\)</span> for the network without needing any information but the adjacency matrix. Consider, for instance, a case where we design a new algorithm for a social network, and we want to know how much more RAM we might need as the social network grows. We might want to investigate how the algorithm scales to networks with different numbers of people and different connection probabilities that might be realistic as our social network expands in popularity. Examining how the algorithm behaves on ER networks with different values of <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span> might be helpful. This is an especially common approach when people deal with networks that are said to be <em>sparse</em>, or where <span class="math notranslate nohighlight">\(p\)</span> is very small (and consequently, there aren’t many edges).</p>
<p>In the next code block, we look to sample a single ER network with <span class="math notranslate nohighlight">\(50\)</span> nodes and an edge probability <span class="math notranslate nohighlight">\(p\)</span> of <span class="math notranslate nohighlight">\(0.3\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">er_np</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># network with 50 vertices</span>
<span class="n">ps</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># probability of an edge existing is .3</span>

<span class="c1"># sample a single adj. mtx from ER(50, .3)</span>
<span class="n">As</span> <span class="o">=</span> <span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">ps</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># and plot it</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">As</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;ER(50, 0.3) Simulation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;ER(50, 0.3) Simulation&#39;}&gt;
</pre></div>
</div>
<img alt="../../_images/single-network-models_2_1.png" src="../../_images/single-network-models_2_1.png" />
</div>
</div>
<p>Above, we visualize the network using a heatmap. The dark red squares indicate that an edge exists between a pair of vertices, and white squares indicate that an edge does not exist between a pair of vertices.</p>
<p>If we already have a network, we might want to assume that the network is an ER network, and investigate the edge probability parameter. Next, we use graspologic to estimate the edge probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.models</span> <span class="kn">import</span> <span class="n">EREstimator</span>

<span class="c1"># instantiate an ER Estimator which is directed with loops</span>
<span class="n">er</span> <span class="o">=</span> <span class="n">EREstimator</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># fit an ER model to As</span>
<span class="n">er</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">As</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ER </span><span class="se">\&quot;</span><span class="s2">p</span><span class="se">\&quot;</span><span class="s2"> parameter: </span><span class="si">{</span><span class="n">er</span><span class="o">.</span><span class="n">p_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ER &quot;p&quot; parameter: 0.298
</pre></div>
</div>
</div>
</div>
<p>As we can see, the edge probability parameter in a directed network with loops is just the average fraction of times <span class="math notranslate nohighlight">\(\pmb A\)</span> has a value of <span class="math notranslate nohighlight">\(1\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average edge weight: </span><span class="si">{</span><span class="n">As</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average edge weight: 0.298
</pre></div>
</div>
</div>
</div>
<p>Note that the <span class="math notranslate nohighlight">\(p\)</span> parameter will be computed differently depending on whether the network is assumed to be directed or undirected, and loopy or hollow. Be careful to specify the appropriate model for the network you have.</p>
<p>Next, let’s see what happens when we use a higher edge probability, like <span class="math notranslate nohighlight">\(p=0.7\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pl</span> <span class="o">=</span> <span class="mf">0.7</span>  <span class="c1"># network has an edge probability of 0.7</span>

<span class="c1"># sample a single adj. mtx from ER(50, 0.7)</span>
<span class="n">Al</span> <span class="o">=</span> <span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">pl</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># and plot it</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">Al</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;ER(50, 0.7) Simulation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:title={&#39;center&#39;:&#39;ER(50, 0.7) Simulation&#39;}&gt;
</pre></div>
</div>
<img alt="../../_images/single-network-models_8_1.png" src="../../_images/single-network-models_8_1.png" />
</div>
</div>
<p>As the edge probability increases, the sampled adjacency matrix tends to indicate that there are more connections in the network. This is because there is a higher chance of an edge existing when <span class="math notranslate nohighlight">\(p\)</span> is larger.</p>
</div>
<div class="section" id="stochastic-block-model-sbm">
<h2>Stochastic Block Model (SBM)<a class="headerlink" href="#stochastic-block-model-sbm" title="Permalink to this headline">¶</a></h2>
<p>Consider the social network above. Using the ER model described above, we can only model the connections between a pair of people with a <em>fixed probability</em> that is the same for all pairs of students within the network. What would happen if we had additional information about students in our network that might influence the probability that they were friends? Consider, for instance, that we know which school each student attends. It seems fairly logical that if two students go to the same school, in general, they will probably have a higher probability of being friends than if they went to different schools. Unfortunately, using the ER model, there is nothing more complex we can do to reflect this fact. This is where the Stochastic Block Model, or SBM, comes into play. The Stochastic Block Model generalizes the ER model, and has the following two parameters:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\vec \tau\)</span>: the vertex community assignment vector for each of the nodes in the network, and</p></li>
<li><p><span class="math notranslate nohighlight">\(\pmb B\)</span>: the symmetric block matrix for each pair of communities.</p></li>
</ol>
<p>With the SBM, we suppose that each node can be assigned to a group of nodes, called a <strong>community</strong>. Instead of describing all pairs of nodes by a fixed probability like with the ER model, in the SBM, we instead describe properties that hold for edges between <em>pairs of communities</em>. We write that <span class="math notranslate nohighlight">\(\vec \tau \in \{1, ..., K\}^n\)</span>, which means that <span class="math notranslate nohighlight">\(\vec \tau\)</span> is an <span class="math notranslate nohighlight">\(n\)</span>-dimensional vector which takes one of <span class="math notranslate nohighlight">\(K\)</span> possible values. In our social network example, for instance, this vector would reflect the fact that each of the <span class="math notranslate nohighlight">\(n\)</span> students in our network could be attendees at one of <span class="math notranslate nohighlight">\(K\)</span> possible schools. For a single node <span class="math notranslate nohighlight">\(i\)</span> that is in community <span class="math notranslate nohighlight">\(\ell\)</span>, where <span class="math notranslate nohighlight">\(\ell \in \{1, ..., K\}\)</span>, we write that <span class="math notranslate nohighlight">\(\tau_i = \ell\)</span>.</p>
<p>Next, let’s discuss the matrix <span class="math notranslate nohighlight">\(\pmb B\)</span>, which is known as the <strong>block matrix</strong> of the SBM. We write down that <span class="math notranslate nohighlight">\(\pmb B \in [0, 1]^{K \times K}\)</span>, which means that the block matrix is a matrix with <span class="math notranslate nohighlight">\(K\)</span> rows and <span class="math notranslate nohighlight">\(K\)</span> columns. If we have a pair of nodes and know which of the <span class="math notranslate nohighlight">\(K\)</span> communities each node is from, the block matrix tells us the probability that those two nodes are connected. This matrix <span class="math notranslate nohighlight">\(\pmb B\)</span> is also symmetric, which means that if <span class="math notranslate nohighlight">\(b_{k, \ell} = p\)</span> where <span class="math notranslate nohighlight">\(p\)</span> is a probability, that <span class="math notranslate nohighlight">\(b_{\ell, k} = p\)</span>, too.</p>
<p>Finally, let’s think about how to write down the generative model for the SBM. Remember that <span class="math notranslate nohighlight">\(\vec \tau\)</span> and <span class="math notranslate nohighlight">\(\pmb B\)</span> are parameters, which means that when we fit a SBM, we know these ahead of time. Intuitionally what we want to reflect is, if we know that node <span class="math notranslate nohighlight">\(i\)</span> is in community <span class="math notranslate nohighlight">\(\ell\)</span> and node <span class="math notranslate nohighlight">\(j\)</span> is in community <span class="math notranslate nohighlight">\(k\)</span>, that the <span class="math notranslate nohighlight">\((\ell, k)\)</span> entry of the block matrix is the probability that <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> are connected. Formally, we write this statement down by saying that <span class="math notranslate nohighlight">\(A_{ij}\)</span> conditioned on <span class="math notranslate nohighlight">\(\tau_i = \ell\)</span> and <span class="math notranslate nohighlight">\(\tau_j = k\)</span> is sampled independently from a <span class="math notranslate nohighlight">\(Bernoulli(b_{\ell, k})\)</span> distribution. Like the ER model, the edges are still independent, which means that edges occuring or not occuring do not have an impact on one another. Unlike above, we can no longer say that the <span class="math notranslate nohighlight">\(A_{ij}\)</span>s are identically distributed, since the probability <span class="math notranslate nohighlight">\(b_{\ell, k}\)</span> depends on the communities that nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> are assigned to. This means that if we were to look at a different pair of nodes, the probability that the two nodes are connected could be different, and therefore they would not share the same distribution.</p>
<p>We just covered a lot of intuition that will be critical for understanding many of the later models, so let’s work through an example. Let’s assume that we have <span class="math notranslate nohighlight">\(100\)</span> students, and we know that each student goes to <span class="math notranslate nohighlight">\(1\)</span> of <span class="math notranslate nohighlight">\(2\)</span> possible schools. We don’t really care too much about the ordering of the students for now, so let’s just assume that the students are organized such that the first <span class="math notranslate nohighlight">\(50\)</span> students all go to school <span class="math notranslate nohighlight">\(1\)</span>, and the second <span class="math notranslate nohighlight">\(50\)</span> students all go to school <span class="math notranslate nohighlight">\(2\)</span>. Let’s assume that the students from school <span class="math notranslate nohighlight">\(1\)</span> are a little bit more closely knit than the students from school <span class="math notranslate nohighlight">\(2\)</span>, so we’ll say that the probability of two students who both go to school <span class="math notranslate nohighlight">\(1\)</span> being connected is <span class="math notranslate nohighlight">\(0.5\)</span>, and the probability of two students who both go to school <span class="math notranslate nohighlight">\(2\)</span> being friends is <span class="math notranslate nohighlight">\(0.3\)</span>. Finally, let’s assume that if one student goes to school <span class="math notranslate nohighlight">\(1\)</span> and the other student goes to school <span class="math notranslate nohighlight">\(2\)</span>, that the probability that they are friends is <span class="math notranslate nohighlight">\(0.2\)</span>.</p>
<div class="admonition-thought-exercise admonition">
<p class="admonition-title">Thought Exercise</p>
<p>Before you read on, try to think to yourself about what the community assignment vector <span class="math notranslate nohighlight">\(\vec \tau\)</span> and the block matrix <span class="math notranslate nohighlight">\(\pmb B\)</span> look like.</p>
</div>
<p>Next, let’s plot what <span class="math notranslate nohighlight">\(\vec \tau\)</span> and <span class="math notranslate nohighlight">\(\pmb B\)</span> look like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">plot_tau</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">([</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="s1">&#39;black&#39;</span><span class="p">])</span>
    <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Vertex Assignment Vector&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tau</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="n">f</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Vector&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># number of students</span>

<span class="c1"># tau is a column vector of 50 1s followed by 50 2s</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>


<span class="n">plot_tau</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">5</span><span class="o">-</span><span class="n">f74203679f3b</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span> 
<span class="g g-Whitespace">     </span><span class="mi">22</span> 
<span class="ne">---&gt; </span><span class="mi">23</span> <span class="n">plot_tau</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>

<span class="nn">&lt;ipython-input-5-f74203679f3b&gt;</span> in <span class="ni">plot_tau</span><span class="nt">(tau, title)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="k">def</span> <span class="nf">plot_tau</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="ne">----&gt; </span><span class="mi">6</span>     <span class="n">cmap</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">([</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="s1">&#39;black&#39;</span><span class="p">])</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>         <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;matplotlib&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>

<span class="c1"># for simplicity, the simulation code generates samples wherein</span>
<span class="c1"># vertices from the same community are ordered in the vertex set by</span>
<span class="c1"># their community order. Note that it would be theoretically equivalent to</span>
<span class="c1"># denote the total number of vertices in each community, or provide</span>
<span class="c1"># a vector tau with the first 50 entries taking the value 1, and the</span>
<span class="c1"># second 50 enties taking the value 0, given this fact.</span>
<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>  <span class="c1"># total number of vertices is the sum of the </span>
<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">[</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">05</span><span class="p">]]</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;SBM(T, B) Simulation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/single-network-models_15_0.png" src="../../_images/single-network-models_15_0.png" />
</div>
</div>
<p>In the above simulation, we can clearly see an apparent <span class="math notranslate nohighlight">\(4\)</span>-“block structure”, which describes the fact that the probability of an edge existing depends upon which of the <span class="math notranslate nohighlight">\(4\)</span> “blocks” the edge falls into. These blocks are the apparent “subgraphs”, or square patterns, observed in the above graph. The block structure is clearly delineated by the first <span class="math notranslate nohighlight">\(50\)</span> vertices being from a single community, and the second <span class="math notranslate nohighlight">\(50\)</span> vertices being from a different community.</p>
<p>It is important to note that a graph may be <span class="math notranslate nohighlight">\(SBM_n(\vec \tau, \pmb B)\)</span> regardless of whether a block structure is visually discernable. Indeed, the block structure may only be apparent given a particular ordering of the vertices, an otherwise, may not even be discernable at all. Consider, for instance, a similar adjacency matrix to the graph plotted above, with the exact same realization, up to a permutation (reordering) of the vertices. The below graph shows the exact same set of adjacencies as-above, but wherein <span class="math notranslate nohighlight">\(\pmb A\)</span> has had its vertices resorted randomly. The graph has an identical block structuure (up to the reordering of the vertices) as the preceding graph illustrated.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># generate a permutation of the n vertices</span>
<span class="n">vtx_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># same adjacency matrix (up to reorder of the vertices)</span>

<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">[[</span><span class="n">vtx_perm</span><span class="p">]]</span> <span class="p">[:,</span><span class="n">vtx_perm</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-11-8581568507e8&gt;:8: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  heatmap(A[[vtx_perm]] [:,vtx_perm])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="../../_images/single-network-models_17_2.png" src="../../_images/single-network-models_17_2.png" />
</div>
</div>
<p>In this sense, it becomes quite difficult in practice to determine whether community structure exists simply by looking at a graph, unless you are looking at a graph in which the vertices are already arranged in an order which respects the community struucture.</p>
</div>
<div class="section" id="structured-independent-edge-model-siem">
<h2>Structured Independent Edge Model (SIEM)<a class="headerlink" href="#structured-independent-edge-model-siem" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="random-dot-product-graph-rdpg">
<h2>Random Dot Product Graph (RDPG)<a class="headerlink" href="#random-dot-product-graph-rdpg" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="generalized-random-dot-product-graph-grdpg">
<h2>Generalized Random Dot Product Graph (GRDPG)<a class="headerlink" href="#generalized-random-dot-product-graph-grdpg" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="degree-corrected-models">
<h2>Degree-Corrected Models<a class="headerlink" href="#degree-corrected-models" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="inhomogeneous-erdos-renyi-ier">
<h2>Inhomogeneous Erdos-Renyi (IER)<a class="headerlink" href="#inhomogeneous-erdos-renyi-ier" title="Permalink to this headline">¶</a></h2>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<p>[1] Erdös P, Rényi A. 1959. “On random graphs, I.” Publ. Math. Debrecen 6:290–297.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="why-use-models.html" title="previous page">Why Use Statistical Models?</a>
    <a class='right-next' id="next-link" href="multi-network-models.html" title="next page">Multi-Network Models</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>