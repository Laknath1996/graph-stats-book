
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.3. Erdös-Rényi (ER) Random Networks &#8212; Hands-on Network Machine Learning with Scikit-Learn and Graspologic</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.5. Stochastic Block Models (SBM)" href="single-network-models_SBM.html" />
    <link rel="prev" title="5.2. Network Models" href="single-network-models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Hands-on Network Machine Learning with Scikit-Learn and Graspologic</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../coverpage.html">
   Hands-on Network Machine Learning with Scikit-Learn and Graspologic
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/terminology.html">
   Terminology and Math Refresher
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch1/ch1.html">
   1. The Network Machine Learning Landscape
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/what-is-a-network.html">
     1.1. What Is A Network?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/why-study-networks.html">
     1.2. Why Study Networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/examples-of-applications.html">
     1.3. Examples of applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-networks.html">
     1.4. Types of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/types-of-learning-probs.html">
     1.5. Types of Network Learning Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/main-challenges.html">
     1.6. Main Challenges of Network Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch1/exercises.html">
     1.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch2/ch2.html">
   2. End-to-end Biology Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/big-picture.html">
     2.1. Look at the big picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/get-the-data.html">
     2.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/prepare-the-data.html">
     2.3. Prepare the Data for Network Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/transformation-techniques.html">
     2.4. Transformation Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/select-and-train.html">
     2.5. Select and Train a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch2/fine-tune.html">
     2.6. Fine-Tune your Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../foundations/ch3/ch3.html">
   3. End-to-end Business Network Machine Learning Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/big-picture.html">
     3.1. Look at the Big Picture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/get-the-data.html">
     3.2. Get the Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/discover-and-visualize.html">
     3.3. Discover and Visualize the Data to Gain Insights
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../foundations/ch3/prepare-the-data.html">
     3.4. Prepare the Data for Network Algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Representations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/ch4.html">
   4. Properties of Networks as a Statistical Object
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/matrix-representations.html">
     4.1. Matrix Representations Of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/network-representations.html">
     4.2. Representations of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/properties-of-networks.html">
     4.3. Properties of Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/regularization.html">
     4.4. Regularization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="ch5.html">
   5. Why Use Statistical Models?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="why-use-models.html">
     5.1. Why Use Statistical Models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models.html">
     5.2. Network Models
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     5.3. Erdös-Rényi (ER) Random Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_SBM.html">
     5.5. Stochastic Block Models (SBM)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="single-network-models_RDPG.html">
     5.6. Random Dot Product Graphs (RDPG)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multi-network-models.html">
     5.9. Multi-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models-with-covariates.html">
     5.10. Network Models with Covariates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch6/ch6.html">
   6. Learning Network Representations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_mle.html">
     6.1. Estimating Parameters in Network Models via MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/why-embed-networks.html">
     6.2. Why embed networks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/spectral-embedding.html">
     6.3. Spectral Embedding Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/estimating-parameters_spectral.html">
     6.4. Estimating Parameters in Network Models via Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/random-walk-diffusion-methods.html">
     6.5. Random-Walk and Diffusion-based Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/graph-neural-networks.html">
     6.6. Graph Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/multigraph-representation-learning.html">
     6.7. Multiple-Network Representation Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch6/joint-representation-learning.html">
     6.8. Joint Representation Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch7/ch7.html">
   7. Theoretical Results
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-single-network.html">
     7.1. Theory for Single Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-multigraph.html">
     7.2. Theory for Multiple-Network Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch7/theory-matching.html">
     7.3. Theory for Graph Matching
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch8/ch8.html">
   8. Leveraging Representations for Single Graph Applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/community-detection.html">
     8.1. Community Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/testing-differences.html">
     8.2. Testing for Differences between Communities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/model-selection.html">
     8.3. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/vertex-nomination.html">
     8.4. Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/anomaly-detection.html">
     8.5. Anomaly Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch8/out-of-sample.html">
     8.6. Out-of-sample Embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch9/ch9.html">
   9. Leveraging Representations for Multiple Graph Applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/two-sample-hypothesis.html">
     9.1. Two-Sample Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/graph-matching-vertex.html">
     9.2. Graph Matching and Vertex Nomination
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch9/vertex-nomination.html">
     9.3. Vertex Nomination
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../applications/ch10/ch10.html">
   10. Algorithms for more than 2 graphs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/anomaly-detection.html">
     10.1. Anomaly Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-edges.html">
     10.2. Testing for Significant Edges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-vertices.html">
     10.3. Testing for Significant Vertices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../applications/ch10/significant-communities.html">
     10.4. Testing for Significant Communities
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://graspologic.readthedocs.io/en/latest/">
   Graspologic Documentation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/representations/ch5/single-network-models_ER.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/neurodata/graph-stats-book/edit/master/representations/ch5/single-network-models_ER.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/neurodata/graph-stats-book/master?urlpath=tree/representations/ch5/single-network-models_ER.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   5.3. Erdös-Rényi (ER) Random Networks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#practical-utility">
     5.3.1. Practical Utility
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probability">
     5.3.2. Probability*
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#network-models-for-networks-which-aren-t-simple">
     5.3.3. Network models for networks which aren’t simple
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#binary-network-model-which-has-loops-but-is-undirected">
       5.3.3.1. Binary network model which has loops, but is undirected
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#binary-network-model-which-is-loopless-but-directed">
       5.3.3.2. Binary network model which is loopless, but directed
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#binary-network-model-which-is-has-loops-and-is-directed">
       5.3.3.3. Binary network model which is has loops and is directed
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   5.4. References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="erdos-renyi-er-random-networks">
<h1><span class="section-number">5.3. </span>Erdös-Rényi (ER) Random Networks<a class="headerlink" href="#erdos-renyi-er-random-networks" title="Permalink to this headline">¶</a></h1>
<p>We will start our description with the simplest random network model. Consider a social network, with <span class="math notranslate nohighlight">\(50\)</span> students. Our network will have <span class="math notranslate nohighlight">\(50\)</span> nodes, where each node represents a single student in the network. Edges in the social network represent whether or not a pair of students are friends. What is the simplest way we could describe whether two people are friends?</p>
<p>In this case, we have a yes or no question: are a pair of people friends, or are they not friends? In this case, the simplest possible thing to do would be to say, for any two students in our network, there is some probability (which we will call <span class="math notranslate nohighlight">\(p\)</span>) that describes how likely they are to be friends. In the below example, for the sake of argument, we will let <span class="math notranslate nohighlight">\(p=0.3\)</span>. What does a realization from this network look like?</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphbook_code</span> <span class="kn">import</span> <span class="n">draw_multiplot</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">er_np</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># network with 50 nodes</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># probability of an edge existing is .3</span>

<span class="c1"># sample a single simple adjacency matrix from ER(50, .3)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;ER(0.3) Simulation&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/single-network-models_ER_1_0.png" src="../../_images/single-network-models_ER_1_0.png" />
</div>
</div>
<p>Using this example, now let’s get down to business. This simple random network model is called the Erdös Rényi (ER) model<sup>1</sup>. The Erdös Rényi model formalizes this relatively simple situation with a single parameter and an <span class="math notranslate nohighlight">\(iid\)</span> assumption:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Space</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(p\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\([0, 1]\)</span></p></td>
<td><p>Probability that an edge exists between a pair of nodes, which is identical for all pairs of nodes</p></td>
</tr>
</tbody>
</table>
<p>From here on out, when we talk about an Erdös Rényi random variable, we will simply call it an ER network. In an ER network, each pair of nodes is connected with probability <span class="math notranslate nohighlight">\(p\)</span>, and therefore not connected with probability <span class="math notranslate nohighlight">\(1-p\)</span>. Statistically, we say that for each edge <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> for every pair of nodes where <span class="math notranslate nohighlight">\(j &gt; i\)</span> (in terms of the adjacency matrix, this means all of the edges in the <em>upper right</em> triangle), that <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> is sampled independently and identically from a <em>Bernoulli</em> distribution with probability <span class="math notranslate nohighlight">\(p\)</span>. The word “independent” means that edges in the network occurring or not occurring do not affect one another. For instance, this means that if we knew a student named Alice was friends with Bob, and Alice was also friends with Chadwick, that we do not learn any information about whether Bob is friends with Chadwick. The word “identical” means that every edge in the network has the same probability <span class="math notranslate nohighlight">\(p\)</span> of being connected. If Alice and Bob are friends with probability <span class="math notranslate nohighlight">\(p\)</span>, then Alice and Chadwick are friends with probability <span class="math notranslate nohighlight">\(p\)</span>, too. We assume here that the networks are undirected, which means that if an edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> exists from node <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ji}\)</span> also exists from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>. We also assume that the networks are loopless, which means that no edges <span class="math notranslate nohighlight">\(\mathbf a_{ii}\)</span> can go from node <span class="math notranslate nohighlight">\(i\)</span> to itself. If <span class="math notranslate nohighlight">\(\mathbf A\)</span> is the adjacency matrix for an ER network with probability <span class="math notranslate nohighlight">\(p\)</span>, we write that <span class="math notranslate nohighlight">\(\mathbf A \sim ER_n(p)\)</span>.</p>
<div class="section" id="practical-utility">
<h2><span class="section-number">5.3.1. </span>Practical Utility<a class="headerlink" href="#practical-utility" title="Permalink to this headline">¶</a></h2>
<p>In practice, the ER model seems like it might be a little too simple to be useful. Why would it ever be useful to think that the best we can do to describe our network is to say that connections exist with some probability? Does this miss a <em>lot</em> of useful questions we might want to answer? Fortunately, there are a number of ways in which the simplicity of the ER model is useful. Given a probability and a number of nodes, we can easily describe the properties we would expect to see in a network if that network were ER. For instance, we know how many edges on average the nodes of an ER nework should have. We can reverse this idea, too: given a network we think might <em>not</em> be ER, we could check whether it’s different in some way from a network which is ER. For instance, if we see that half the nodes have a ton of edges (meaning, they have a high degree), and half don’t, we should probably use a more complicated model than an Erdos-Renyi. If this is the case, we might look for other models that could describe our network which are more complex.</p>
<div class="admonition-working-out-the-expected-degree-in-an-erd-ouml-s-r-eacute-nyi-network admonition">
<p class="admonition-title">Working Out the Expected Degree in an Erdös-Rényi Network</p>
<p>Suppose that <span class="math notranslate nohighlight">\(\mathbf A\)</span> is a simple network which is random. The network has <span class="math notranslate nohighlight">\(n\)</span> nodes <span class="math notranslate nohighlight">\(\mathcal V = (v_i)_{i = 1}^n\)</span>. Recall that the in a simple network, the node degree is <span class="math notranslate nohighlight">\(deg(v_i) = \sum_{j = 1}^n \mathbf a_{ij}\)</span>. What is the expected degree of a node <span class="math notranslate nohighlight">\(v_i\)</span> of a random network <span class="math notranslate nohighlight">\(\mathbf A\)</span> which is Erdös-Rényi?</p>
<p>To describe this, we will compute the expectated value of the degree <span class="math notranslate nohighlight">\(deg(v_i)\)</span>, written <span class="math notranslate nohighlight">\(\mathbb E\left[deg(v_i)\right]\)</span>. Let’s see what happens:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i)\right] &amp;= \mathbb E\left[\sum_{j = 1}^n \mathbf a_{ij}\right] \\
    &amp;= \sum_{j = 1}^n \mathbb E[\mathbf a_{ij}]
\end{align*}\]</div>
<p>We use the <em>linearity of expectation</em> in the line above, which means that the expectation of a sum with a finite number of terms being summed over (<span class="math notranslate nohighlight">\(n\)</span>, in this case) is the sum of the expectations. Finally, by definition, all of the edges <span class="math notranslate nohighlight">\(A_{ij}\)</span> have the same distribution: <span class="math notranslate nohighlight">\(Bern(p)\)</span>. The expected value of a random quantity which takes a Bernoulli distribution is just the probability <span class="math notranslate nohighlight">\(p\)</span>. This means every term <span class="math notranslate nohighlight">\(\mathbb E[\mathbf a_{ij}] = p\)</span>. Therefore:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb E\left[deg(v_i)\right] &amp;= \sum_{j = 1}^n p = n\cdot p
\end{align*}\]</div>
<p>Since all of the <span class="math notranslate nohighlight">\(n\)</span> terms being summed have the same expected value. This holds for <em>every</em> node <span class="math notranslate nohighlight">\(v_i\)</span>, which means that the expected degree of all nodes is an undirected ER network is the same number, <span class="math notranslate nohighlight">\(n \cdot p\)</span>.</p>
</div>
<!-- The ER model is also useful for the development of new computational techniques to use on random networks. This is because even if the "best" model for a network is something much more complex, we can still calculate an edge probability $p$ for the network without needing any information but the adjacency matrix. Consider, for instance, a case where we design a new algorithm for a social network, and we want to know how much more RAM we might need as the social network grows. We might want to investigate how the algorithm scales to networks with different numbers of people and different connection probabilities that might be realistic as our social network expands in popularity. Examining how the algorithm operates on ER networks with different values of $n$ and $p$ might be helpful. This is an especially common approach when people deal with networks that are said to be *sparse*. A **sparse network** is a network in which the number of edges is much less than the total possible number of edges. This contrasts with a **dense network**, which is a network in which the number of edges is close to the maximum number of possible edges. In the case of an $ER_{n}(p)$ network, the network is sparse when $p$ is small (closer to $0$), and dense when $p$ is large (closer to $1$). -->
<p>In the next code block, we are going to sample a single ER network with <span class="math notranslate nohighlight">\(50\)</span> nodes and an edge probability <span class="math notranslate nohighlight">\(p\)</span> of <span class="math notranslate nohighlight">\(0.3\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># network with 50 nodes</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># probability of an edge existing is .3</span>

<span class="c1"># sample a single simple adjacency matrix from ER(50, .3)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># and plot it</span>
<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$ER_</span><span class="si">{50}</span><span class="s2">(0.3)$ Simulation&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/single-network-models_ER_4_0.png" src="../../_images/single-network-models_ER_4_0.png" />
</div>
</div>
<p>Above, we visualize the network using a heatmap. The dark squares indicate that an edge exists between a pair of nodes, and white squares indicate that an edge does not exist between a pair of nodes.</p>
<p>Next, let’s see what happens when we use a higher edge probability, like <span class="math notranslate nohighlight">\(p=0.7\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.7</span>  <span class="c1"># network has an edge probability of 0.7</span>

<span class="c1"># sample a single adjacency matrix from ER(50, 0.7)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">er_np</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loops</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># and plot it</span>
<span class="n">draw_multiplot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;$ER_</span><span class="si">{50}</span><span class="s2">(0.7)$ Simulation&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/single-network-models_ER_7_0.png" src="../../_images/single-network-models_ER_7_0.png" />
</div>
</div>
<p>As the edge probability increases, the sampled adjacency matrix tends to indicate that there are more connections in the network. This is because there is a higher chance of an edge existing when <span class="math notranslate nohighlight">\(p\)</span> is larger.</p>
</div>
<div class="section" id="probability">
<h2><span class="section-number">5.3.2. </span>Probability*<a class="headerlink" href="#probability" title="Permalink to this headline">¶</a></h2>
<p>What is the probability for realizations of Erdös-Rényi networks? Remember that for Independent-edge graphs, that the probability can be written:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P_{\theta}(A) &amp;= \prod_{j &gt; i} \mathbb P_\theta(\mathbf{a}_{ij} = a_{ij})
\end{align*}\]</div>
<p>Next, we recall that by assumption of the ER model, that the probability matrix <span class="math notranslate nohighlight">\(P = (p)\)</span>, or that <span class="math notranslate nohighlight">\(p_{ij} = p\)</span> for all <span class="math notranslate nohighlight">\(i,j\)</span>. Therefore:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \mathbb P_\theta(A) &amp;= \prod_{j &gt; i} p^{a_{ij}}(1 - p)^{1 - a_{ij}} \\
    &amp;= p^{\sum_{j &gt; i} a_{ij}} \cdot (1 - p)^{\binom{n}{2} - \sum_{j &gt; i}a_{ij}} \\
    &amp;= p^{m} \cdot (1 - p)^{\binom{n}{2} - m}
\end{align*}\]</div>
<p>This means that the probability <span class="math notranslate nohighlight">\(\mathbb P_\theta(A)\)</span> is a function <em>only</em> of the number of edges <span class="math notranslate nohighlight">\(m = \sum_{j &gt; i}a_{ij}\)</span> in the network represented by adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>. The equivalence class on the Erdös-Rényi networks are the sets:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    E_{i} &amp;= \left\{A \in \mathcal A_n : m = i\right\}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(i\)</span> index from <span class="math notranslate nohighlight">\(0\)</span> (the minimum number of edges possible) all the way up to <span class="math notranslate nohighlight">\(n^2\)</span> (the maximum number of edges possible). All of the relationships for equivalence classes discussed above apply to the sets <span class="math notranslate nohighlight">\(E_i\)</span>.</p>
</div>
<div class="section" id="network-models-for-networks-which-aren-t-simple">
<h2><span class="section-number">5.3.3. </span>Network models for networks which aren’t simple<a class="headerlink" href="#network-models-for-networks-which-aren-t-simple" title="Permalink to this headline">¶</a></h2>
<p>To make the discussions a little more easy to handle, in the above descriptions and all our successive descriptions, we will describe network models for <strong>simple networks</strong>. To recap, networks which are simple are binary networks which are both loopless and undirected. Stated another way, simple networks are networks whose adjacency matrices are only <span class="math notranslate nohighlight">\(0\)</span>s and <span class="math notranslate nohighlight">\(1\)</span>s, they are hollow (the diagonal is entirely <em>0</em>), and symmetric (the lower and right triangles of the adjacency matrix are the <em>same</em>). What happens our networks don’t quite look this way?</p>
<p>For now, we’ll keep the assumption that the networks are binary, but we will discuss non-binary network models in a later chapter. We have three possibilities we can consider, and we will show how the “relaxations” of the assumptions change a description of a network model. A <em>relaxation</em>, in statistician speak, means that we are taking the assumptions that we had (in this case, that the networks are <em>simple</em>), and progressively making the assumptions weaker (more <em>relaxed</em>) so that they apply to other networks, too. We split these out so we can be as clear as possible about how the generative model changes with each relaxation step.</p>
<p>We will compare each relaxation to the statement about the generative model for the ER generative model. To recap, for a simple network, we wrote:</p>
<p>“Statistically, we say that for each edge <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> for every pair of nodes where <span class="math notranslate nohighlight">\(j &gt; i\)</span> (in terms of the adjacency matrix, this means all of the nodes in the <em>upper right</em> triangle), that <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> is sampled independently and identically from a <em>Bernoulli</em> distribution with probability <span class="math notranslate nohighlight">\(p\)</span>….  We assume here that the networks are undirected, which means that if an edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> exists from node <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ji}\)</span> also exists from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>. We also assume that the networks are loopless, which means that no edges <span class="math notranslate nohighlight">\(\mathbf a_{ii}\)</span> can go from node <span class="math notranslate nohighlight">\(i\)</span> to itself.”</p>
<p>Any additional parts that are added are expressed in <strong><font color='green'>green</font></strong> font. Omitted parts are struck through with <font color='red'><strike>red</strike></font> font.</p>
<p>Note that these generalizations apply to <em>any</em> of the successive networks which we describe in the Network Models section, and not just the ER model!</p>
<div class="section" id="binary-network-model-which-has-loops-but-is-undirected">
<h3><span class="section-number">5.3.3.1. </span>Binary network model which has loops, but is undirected<a class="headerlink" href="#binary-network-model-which-has-loops-but-is-undirected" title="Permalink to this headline">¶</a></h3>
<p>Here, all we want to do is relax the assumption that the network is loopless. We simply ignore the statement that edges <span class="math notranslate nohighlight">\(\mathbf a_{ii}\)</span> cannot exist, and allow that the <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> which follow a Bernoulli distribution (with some probability which depends on the network model choice) <em>now</em> applies to <span class="math notranslate nohighlight">\(j \geq i\)</span>, and not just <span class="math notranslate nohighlight">\(j &gt; i\)</span>. We keep that an edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> existing implies that <span class="math notranslate nohighlight">\(\mathbf a_{ji}\)</span> also exists, which maintains the symmetry of <span class="math notranslate nohighlight">\(\mathbf A\)</span> (and consequently, the undirectedness of the network).</p>
<p>Our description of the ER network changes to:</p>
<p>Statistically, we say that for each edge <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> for every pair of nodes where <span class="math notranslate nohighlight">\(\mathbf{\color{green}{j \geq i}}\)</span> (in terms of the adjacency matrix, this means all of the nodes in the <em>upper right</em> triangle <strong><font color='green'>and the diagonal</font></strong>), that <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> is sampled independently and identically from a <em>Bernoulli</em> distribution with probability <span class="math notranslate nohighlight">\(p\)</span>….  We assume here that the networks are undirected, which means that if an edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> exists from node <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ji}\)</span> also exists from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>. <font color='red'><strike>We also assume that the networks are loopless, which means that no edges <span class="math notranslate nohighlight">\(\mathbf a_{ii}\)</span> can go from node <span class="math notranslate nohighlight">\(i\)</span> to itself.</strike></font></p>
</div>
<div class="section" id="binary-network-model-which-is-loopless-but-directed">
<h3><span class="section-number">5.3.3.2. </span>Binary network model which is loopless, but directed<a class="headerlink" href="#binary-network-model-which-is-loopless-but-directed" title="Permalink to this headline">¶</a></h3>
<p>Like above, we simply ignore the statement that <span class="math notranslate nohighlight">\(\mathbf a_{ji} = \mathbf a_{ij}\)</span>, which removes the symmetry of <span class="math notranslate nohighlight">\(\mathbf A\)</span> (and consequently, removes the undirectedness of the network). We allow that the <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> which follows a Bernoulli distribution now apply to <span class="math notranslate nohighlight">\(j \neq i\)</span>, and not just <span class="math notranslate nohighlight">\(j &gt; i\)</span>. We keep that <span class="math notranslate nohighlight">\(\mathbf a_{ii} = 0\)</span>, which maintains the hollowness of <span class="math notranslate nohighlight">\(\mathbf A\)</span> (and consequently, the undirectedness of the network).</p>
<p>Our description of the ER network changes to:</p>
<p>Statistically, we say that for each edge <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> for every pair of nodes where <span class="math notranslate nohighlight">\(\mathbf{\color{green}{j \neq i}}\)</span> (in terms of the adjacency matrix, this means all of the nodes <strike><font color='red'>in the <em>upper right</em> triangle</font></strike><strong><font color='green'>which are not along the diagonal</font></strong>), that <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> is sampled independently and identically from a <em>Bernoulli</em> distribution with probability <span class="math notranslate nohighlight">\(p\)</span>….  <font color='red'><strike>We assume here that the networks are undirected, which means that if an edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> exists from node <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ji}\)</span> also exists from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>.</strike></font> We also assume that the networks are loopless, which means that no edges <span class="math notranslate nohighlight">\(\mathbf a_{ii}\)</span> can go from node <span class="math notranslate nohighlight">\(i\)</span> to itself.</p>
</div>
<div class="section" id="binary-network-model-which-is-has-loops-and-is-directed">
<h3><span class="section-number">5.3.3.3. </span>Binary network model which is has loops and is directed<a class="headerlink" href="#binary-network-model-which-is-has-loops-and-is-directed" title="Permalink to this headline">¶</a></h3>
<p>Finally, for a network which has loops and is directed, we combine the above two approaches. We ignore the statements that <span class="math notranslate nohighlight">\(\mathbf a_{ji} = \mathbf a_{ij}\)</span>, and the statement that <span class="math notranslate nohighlight">\(\mathbf a_{ii} = 0\)</span>.</p>
<p>Our descriptiomn of the ER network changes to:</p>
<p>Statistically, we say that for each edge <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span>  <font color='red'><strike>where <span class="math notranslate nohighlight">\(j &gt; i\)</span> (in terms of the adjacency matrix, this means all of the nodes in the <em>upper right</em> triangle)</strike></font>, that <span class="math notranslate nohighlight">\(\mathbf{a}_{ij}\)</span> is sampled independently and identically from a <em>Bernoulli</em> distribution with probability <span class="math notranslate nohighlight">\(p\)</span>, <font color='green'>for all possible combinations of nodes <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(i\)</span></font>. <font color='red'><strike>We assume here that the networks are undirected, which means that if an edge <span class="math notranslate nohighlight">\(\mathbf a_{ij}\)</span> exists from node <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>, then the edge <span class="math notranslate nohighlight">\(\mathbf a_{ji}\)</span> also exists from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>. We also assume that the networks are loopless, which means that no edges <span class="math notranslate nohighlight">\(\mathbf a_{ii}\)</span> can go from node <span class="math notranslate nohighlight">\(i\)</span> to itself.</strike></font></p>
</div>
</div>
</div>
<div class="section" id="references">
<h1><span class="section-number">5.4. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<p>[1] Erdös P, Rényi A. 1959. “On random graphs, I.” Publ. Math. Debrecen 6:290–297.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./representations/ch5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="single-network-models.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">5.2. </span>Network Models</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="single-network-models_SBM.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">5.5. </span>Stochastic Block Models (SBM)</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Joshua Vogelstein, Alex Loftus, and Eric Bridgeford<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>